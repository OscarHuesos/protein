import keras_metrics as km
import pandas as pd
import numpy as np
import re
import seaborn as sn
from io import StringIO
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.losses import sparse_categorical_crossentropy
#from tensorflow.keras.optimizers import Adam
#from kerastuner.tuners import RandomSearch
from sklearn.metrics import matthews_corrcoef
from sklearn.naive_bayes import GaussianNB
from sklearn import preprocessing
from sklearn.preprocessing import label_binarize
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC,SVR
from keras.utils import to_categorical
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.model_selection import cross_val_score, KFold, train_test_split
from sklearn.model_selection import RepeatedKFold, cross_validate, StratifiedKFold
from sklearn.metrics import make_scorer, accuracy_score
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
from sklearn.metrics import plot_roc_curve,roc_curve, classification_report
from sklearn.metrics import confusion_matrix, plot_confusion_matrix
from sklearn.metrics import  make_scorer,roc_auc_score, auc
import matplotlib.pylab as plt


data=np.genfromtxt("interface_data_sola.csv", delimiter=',', skip_header=1)
#print("data")
#print(data)
#X=data[:,0:6]
#Y=data[:,7]
#print(X)
#print(Y)
#print(Y.astype)
#y = label_binarize(Y, classes=[0, 1])
#yy=np.ravel(y)
#nc = len(yy)
#print("y")
#print(yy)
micros_f1=[]
micros_f1_bag=[]
MCC=[]
MCC_bag=[]
estimators=[]
#fig_f1 = plt.figure(figsize=[12,12])
#ax1 = fig_f1.add_subplot(111,aspect = 'auto')
#fig_mcc = plt.figure(figsize=[12,12])
#ax2 = fig_mcc.add_subplot(111,aspect = 'auto')
train, test = train_test_split(data, test_size=0.30,random_state=42)
#train, test = train_test_split(data, test_size=0.50,
#random_state=42)
print(train.size)
print("train en total")
print(train)
print(len(train))
X_test=test[:,0:6]
Y_test=test[:,7]
y_test = label_binarize(Y_test, classes=[0, 1])
y_test=np.ravel(y_test)

train_10, test_10 = train_test_split(train, test_size=0.90,
random_state=42)
X_10=train_10[:,0:6]
Y_10=train_10[:,7]
y_10 = label_binarize(Y_10, classes=[0, 1])
y_10=np.ravel(y_10)
#nc = len(yy)
#print("y")
print(y_10)
rfc_10 = RandomForestClassifier(n_estimators= 1000,
criterion='entropy', oob_score=True, max_depth=100)
print("train en 10%")
print(train_10)
print(len(train_10))
#print(test_10)
#print(len(test_10))
rfc_10_result=rfc_10.fit(X_10, y_10)
print("Reporte de clasifocacion forest:")
print()
y_rfc_10 =rfc_10_result.predict(X_test)
print(confusion_matrix(y_rfc_10, y_test ))
print(classification_report( y_rfc_10, y_test))
print()
micro_f1_10 = f1_score(y_rfc_10, y_test, average='micro')
print("f1 score micro")
print(micro_f1_10)
OOB_10=rfc_10_result.oob_score_
print("OOB error:")
print(OOB_10)
IMP_10=rfc_10_result.feature_importances_.argsort()
print("Mejores caracteristicas")
print(IMP_10)
MCC_forest_10=matthews_corrcoef(y_rfc_10, y_test)
print("MCC forest:")
print(MCC_forest_10)
micros_f1.append(micro_f1_10)
MCC.append(MCC_forest_10)

bag_10=BaggingClassifier(rfc_10,
n_estimators=50, random_state=0)
bag_results_10=bag_10.fit(X_10, y_10)
y_rfc_10_bag =bag_results_10.predict(X_test)
print("Reporte de clasifocacion forest bag:")
print()
print(confusion_matrix(y_rfc_10_bag, y_test ))
print(classification_report( y_rfc_10_bag, y_test))
micro_f1_10_bag = f1_score(y_rfc_10_bag, y_test, average='micro')
print("f1 score micro bag")
print(micro_f1_10_bag)
#OOB_10_bag=bag_results_10.oob_score_
#print("OOB error bag:")
#print(OOB_10_bag)
#IMP_10_bag=bag_results_10.feature_importances_.argsort()
#print("Mejores caracteristicas")
#print(IMP_10_bag)
#fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_test, y_rfc,pos_label=1)
#auc_forest = auc(fpr_forest, tpr_forest)
MCC_forest_10_bag = matthews_corrcoef(y_rfc_10_bag , y_test)
print("MCC forest bag:")
print(MCC_forest_10_bag)
micros_f1_bag.append(micro_f1_10_bag)
MCC_bag.append(MCC_forest_10_bag)
#print(trees)
#estimators.append(trees)

train_20, test_20 = train_test_split(train, test_size=0.80,
random_state=42)
X_20=train_20[:,0:6]
Y_20=train_20[:,7]
y_20 = label_binarize(Y_20, classes=[0, 1])
y_20=np.ravel(y_20)
print(y_20)
rfc_20 = RandomForestClassifier(n_estimators= 1000,
criterion='entropy', oob_score=True, max_depth=100)
print("train en 20%")
print(train_20)
print(len(train_20))
#print(test_10)
#print(len(test_10))
rfc_20_result=rfc_20.fit(X_20, y_20)
print("Reporte de clasifocacion forest:")
print()
y_rfc_20 =rfc_20_result.predict(X_test)
print(confusion_matrix(y_rfc_20, y_test ))
print(classification_report( y_rfc_20, y_test))
print()
micro_f1_20 = f1_score(y_rfc_20, y_test, average='micro')
print("f1 score micro")
print(micro_f1_20)
#fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_test, y_rfc,pos_label=1)
#auc_forest = auc(fpr_forest, tpr_forest)
MCC_forest_20=matthews_corrcoef(y_rfc_20, y_test)
print("MCC forest:")
print(MCC_forest_20)
micros_f1.append(micro_f1_20)
MCC.append(MCC_forest_20)
OOB_20=rfc_20_result.oob_score_
print("OOB error:")
print(OOB_20)
IMP_20=rfc_20_result.feature_importances_.argsort()
print("Mejores caracteristicas")
print(IMP_20)

bag_20=BaggingClassifier(rfc_20,
n_estimators=50, random_state=0)
bag_results_20 = bag_20.fit(X_20, y_20)
y_rfc_20_bag =bag_results_20.predict(X_test)
print("Reporte de clasifocacion forest bag:")
print()
print(confusion_matrix(y_rfc_20_bag, y_test ))
print(classification_report( y_rfc_20_bag, y_test))
micro_f1_20_bag = f1_score(y_rfc_20_bag, y_test, average='micro')
print("f1 score micro bag")
print(micro_f1_20_bag)
#fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_test, y_rfc,pos_label=1)
#auc_forest = auc(fpr_forest, tpr_forest)
MCC_forest_20_bag = matthews_corrcoef(y_rfc_20_bag , y_test)
print("MCC forest bag:")
print(MCC_forest_20_bag)
micros_f1_bag.append(micro_f1_20_bag)
MCC_bag.append(MCC_forest_20_bag)

train_30, test_30 = train_test_split(train, test_size=0.70,
random_state=42)
X_30=train_30[:,0:6]
Y_30=train_30[:,7]
y_30 = label_binarize(Y_30, classes=[0, 1])
y_30=np.ravel(y_30)
print(y_30)
rfc_30 = RandomForestClassifier(n_estimators= 1000,
criterion='entropy', oob_score=True, max_depth=100)
print("train en 30%")
print(train_30)
print(len(train_30))
rfc_30_result=rfc_30.fit(X_30, y_30)
print("Reporte de clasifocacion forest:")
print()
y_rfc_30 =rfc_30_result.predict(X_test)
print(confusion_matrix(y_rfc_30, y_test ))
print(classification_report( y_rfc_30, y_test))
print()
micro_f1_30 = f1_score(y_rfc_30, y_test, average='micro')
print("f1 score micro")
print(micro_f1_30)
OOB_30 = rfc_30_result.oob_score_
print("OOB error:")
print(OOB_30)
IMP_30=rfc_30_result.feature_importances_.argsort()
print("Mejores caracteristicas")
print(IMP_30)
#fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_test, y_rfc,pos_label=1)
#auc_forest = auc(fpr_forest, tpr_forest)
MCC_forest_30=matthews_corrcoef(y_rfc_30, y_test)
print("MCC forest:")
print(MCC_forest_30)
micros_f1.append(micro_f1_30)
MCC.append(MCC_forest_30)

bag_30=BaggingClassifier(rfc_30,
n_estimators=50, random_state=0)
bag_results_30=bag_30.fit(X_30, y_30)
y_rfc_30_bag =bag_results_30.predict(X_test)
print("Reporte de clasifocacion forest bag:")
print()
print(confusion_matrix(y_rfc_30_bag, y_test ))
print(classification_report( y_rfc_30_bag, y_test))
micro_f1_30_bag = f1_score(y_rfc_30_bag, y_test, average='micro')
print("f1 score micro bag")
print(micro_f1_30_bag)
#fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_test, y_rfc,pos_label=1)
#auc_forest = auc(fpr_forest, tpr_forest)
MCC_forest_30_bag = matthews_corrcoef(y_rfc_30_bag , y_test)
print("MCC forest bag:")
print(MCC_forest_30_bag)
micros_f1_bag.append(micro_f1_30_bag)
MCC_bag.append(MCC_forest_30_bag)

train_40, test_40 = train_test_split(train, test_size=0.60,
random_state=42)
X_40=train_40[:,0:6]
Y_40=train_40[:,7]
y_40 = label_binarize(Y_40, classes=[0, 1])
y_40=np.ravel(y_40)
print(y_40)
rfc_40 = RandomForestClassifier(n_estimators= 1000,
criterion='entropy', oob_score=True, max_depth=100)
print("train en 40%")
print(train_40)
print(len(train_40))
rfc_40_result=rfc_40.fit(X_40, y_40)
print("Reporte de clasifocacion forest:")
print()
y_rfc_40 =rfc_40_result.predict(X_test)
print(confusion_matrix(y_rfc_40, y_test ))
print(classification_report( y_rfc_40, y_test))
print()
micro_f1_40 = f1_score(y_rfc_40, y_test, average='micro')
print("f1 score micro")
print(micro_f1_40)
OOB_40 = rfc_40_result.oob_score_
print("OOB error:")
print(OOB_40)
IMP_40 = rfc_40_result.feature_importances_.argsort()
print("Mejores caracteristicas")
print(IMP_40)
#fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_test, y_rfc,pos_label=1)
#auc_forest = auc(fpr_forest, tpr_forest)
MCC_forest_40=matthews_corrcoef(y_rfc_40, y_test)
print("MCC forest:")
print(MCC_forest_40)
micros_f1.append(micro_f1_40)
MCC.append(MCC_forest_40)

bag_40=BaggingClassifier(rfc_40,
n_estimators=50, random_state=0)
bag_results_40=bag_40.fit(X_40, y_40)
y_rfc_40_bag =bag_results_40.predict(X_test)
print("Reporte de clasifocacion forest bag:")
print()
print(confusion_matrix(y_rfc_40_bag, y_test ))
print(classification_report( y_rfc_40_bag, y_test))
micro_f1_40_bag = f1_score(y_rfc_40_bag, y_test, average='micro')
print("f1 score micro bag")
print(micro_f1_40_bag)
#fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_test, y_rfc,pos_label=1)
#auc_forest = auc(fpr_forest, tpr_forest)
MCC_forest_40_bag = matthews_corrcoef(y_rfc_40_bag , y_test)
print("MCC forest bag:")
print(MCC_forest_40_bag)
micros_f1_bag.append(micro_f1_40_bag)
MCC_bag.append(MCC_forest_40_bag)

train_50, test_50 = train_test_split(train, test_size=0.50,
random_state=42)
X_50=train_50[:,0:6]
Y_50=train_50[:,7]
y_50 = label_binarize(Y_50, classes=[0, 1])
y_50=np.ravel(y_50)
print(y_50)
rfc_50 = RandomForestClassifier(n_estimators= 1000,
criterion='entropy', oob_score=True, max_depth=100)
print("train en 50%")
print(train_50)
print(len(train_50))
rfc_50_result=rfc_50.fit(X_50, y_50)
print("Reporte de clasifocacion forest:")
print()
y_rfc_50 =rfc_50_result.predict(X_test)
print(confusion_matrix(y_rfc_50, y_test ))
print(classification_report( y_rfc_50, y_test))
print()
micro_f1_50 = f1_score(y_rfc_50, y_test, average='micro')
print("f1 score micro")
print(micro_f1_50)
OOB_50 = rfc_50_result.oob_score_
print("OOB error:")
print(OOB_50)
IMP_50 = rfc_50_result.feature_importances_.argsort()
print("Mejores caracteristicas")
print(IMP_50)
#fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_test, y_rfc,pos_label=1)
#auc_forest = auc(fpr_forest, tpr_forest)
MCC_forest_50 = matthews_corrcoef(y_rfc_50, y_test)
print("MCC forest:")
print(MCC_forest_50)
micros_f1.append(micro_f1_50)
MCC.append(MCC_forest_50)

bag_50=BaggingClassifier(rfc_50,
n_estimators=50, random_state=0)
bag_results_50=bag_50.fit(X_50, y_50)
y_rfc_50_bag =bag_results_50.predict(X_test)
print("Reporte de clasifocacion forest bag:")
print()
print(confusion_matrix(y_rfc_50_bag, y_test ))
print(classification_report( y_rfc_50_bag, y_test))
micro_f1_50_bag = f1_score(y_rfc_50_bag, y_test, average='micro')
print("f1 score micro bag")
print(micro_f1_50_bag)
#fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_test, y_rfc,pos_label=1)
#auc_forest = auc(fpr_forest, tpr_forest)
MCC_forest_50_bag = matthews_corrcoef(y_rfc_50_bag , y_test)
print("MCC forest bag:")
print(MCC_forest_50_bag)
micros_f1_bag.append(micro_f1_50_bag)
MCC_bag.append(MCC_forest_50_bag)

train_60, test_60 = train_test_split(train, test_size=0.40,
random_state=42)
X_60=train_60[:,0:6]
Y_60=train_60[:,7]
y_60 = label_binarize(Y_60, classes=[0, 1])
y_60=np.ravel(y_60)
print(y_60)
rfc_60 = RandomForestClassifier(n_estimators= 1000,
criterion='entropy', oob_score=True, max_depth=100)
print("train en 60%")
print(train_60)
print(len(train_60))
rfc_60_result=rfc_60.fit(X_60, y_60)
print("Reporte de clasifocacion forest:")
print()
y_rfc_60 =rfc_60_result.predict(X_test)
print(confusion_matrix(y_rfc_60, y_test ))
print(classification_report( y_rfc_60, y_test))
print()
micro_f1_60 = f1_score(y_rfc_60, y_test, average='micro')
print("f1 score micro")
print(micro_f1_60)
OOB_60 = rfc_60_result.oob_score_
print("OOB error:")
print(OOB_60)
IMP_60 = rfc_60_result.feature_importances_.argsort()
print("Mejores caracteristicas")
print(IMP_60)
#fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_test, y_rfc,pos_label=1)
#auc_forest = auc(fpr_forest, tpr_forest)
MCC_forest_60 = matthews_corrcoef(y_rfc_60, y_test)
print("MCC forest:")
print(MCC_forest_60)
micros_f1.append(micro_f1_60)
MCC.append(MCC_forest_60)

bag_60=BaggingClassifier(rfc_60,
n_estimators=50, random_state=0)
bag_results_60=bag_60.fit(X_60, y_60)
y_rfc_60_bag =bag_results_60.predict(X_test)
print("Reporte de clasifocacion forest bag:")
print()
print(confusion_matrix(y_rfc_60_bag, y_test ))
print(classification_report( y_rfc_60_bag, y_test))
micro_f1_60_bag = f1_score(y_rfc_60_bag, y_test, average='micro')
print("f1 score micro bag")
print(micro_f1_60_bag)
#fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_test, y_rfc,pos_label=1)
#auc_forest = auc(fpr_forest, tpr_forest)
MCC_forest_60_bag = matthews_corrcoef(y_rfc_60_bag , y_test)
print("MCC forest bag:")
print(MCC_forest_60_bag)
micros_f1_bag.append(micro_f1_60_bag)
MCC_bag.append(MCC_forest_60_bag)

train_70, test_70 = train_test_split(train, test_size=0.30,
random_state=42)
X_70=train_70[:,0:6]
Y_70=train_70[:,7]
y_70 = label_binarize(Y_70, classes=[0, 1])
y_70=np.ravel(y_70)
print(y_70)
rfc_70 = RandomForestClassifier(n_estimators= 1000,
criterion='entropy', oob_score=True, max_depth=100)
print("train en 70%")
print(train_70)
print(len(train_70))
rfc_70_result=rfc_70.fit(X_70, y_70)
print("Reporte de clasifocacion forest:")
print()
y_rfc_70 =rfc_70_result.predict(X_test)
print(confusion_matrix(y_rfc_70, y_test ))
print(classification_report( y_rfc_70, y_test))
print()
micro_f1_70 = f1_score(y_rfc_70, y_test, average='micro')
print("f1 score micro")
print(micro_f1_70)
OOB_70 = rfc_70_result.oob_score_
print("OOB error:")
print(OOB_70)
IMP_70 = rfc_70_result.feature_importances_.argsort()
print("Mejores caracteristicas")
print(IMP_70)
#fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_test, y_rfc,pos_label=1)
#auc_forest = auc(fpr_forest, tpr_forest)
MCC_forest_70 = matthews_corrcoef(y_rfc_70, y_test)
print("MCC forest:")
print(MCC_forest_70)
micros_f1.append(micro_f1_70)
MCC.append(MCC_forest_70)

bag_70=BaggingClassifier(rfc_70,
n_estimators=50, random_state=0)
bag_results_70=bag_70.fit(X_70, y_70)
y_rfc_70_bag =bag_results_70.predict(X_test)
print("Reporte de clasifocacion forest bag:")
print()
print(confusion_matrix(y_rfc_70_bag, y_test ))
print(classification_report( y_rfc_70_bag, y_test))
micro_f1_70_bag = f1_score(y_rfc_70_bag, y_test, average='micro')
print("f1 score micro bag")
print(micro_f1_70_bag)
#fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_test, y_rfc,pos_label=1)
#auc_forest = auc(fpr_forest, tpr_forest)
MCC_forest_70_bag = matthews_corrcoef(y_rfc_70_bag , y_test)
print("MCC forest bag:")
print(MCC_forest_70_bag)
micros_f1_bag.append(micro_f1_70_bag)
MCC_bag.append(MCC_forest_70_bag)

train_80, test_80 = train_test_split(train, test_size=0.20,
random_state=42)
X_80=train_80[:,0:6]
Y_80=train_80[:,7]
y_80 = label_binarize(Y_80, classes=[0, 1])
y_80=np.ravel(y_80)
print(y_80)
rfc_80 = RandomForestClassifier(n_estimators= 1000,
criterion='entropy', oob_score=True, max_depth=100)
print("train en 80%")
print(train_80)
print(len(train_80))
rfc_80_result=rfc_80.fit(X_80, y_80)
print("Reporte de clasifocacion forest:")
print()
y_rfc_80 =rfc_80_result.predict(X_test)
print(confusion_matrix(y_rfc_80, y_test ))
print(classification_report( y_rfc_80, y_test))
print()
micro_f1_80 = f1_score(y_rfc_80, y_test, average='micro')
print("f1 score micro")
print(micro_f1_80)
OOB_80 = rfc_80_result.oob_score_
print("OOB error:")
print(OOB_80)
IMP_80 = rfc_80_result.feature_importances_.argsort()
print("Mejores caracteristicas")
print(IMP_80)
#fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_test, y_rfc,pos_label=1)
#auc_forest = auc(fpr_forest, tpr_forest)
MCC_forest_80 = matthews_corrcoef(y_rfc_80, y_test)
print("MCC forest:")
print(MCC_forest_80)
micros_f1.append(micro_f1_80)
MCC.append(MCC_forest_80)

bag_80=BaggingClassifier(rfc_80,
n_estimators=50, random_state=0)
bag_results_80=bag_80.fit(X_80, y_80)
y_rfc_80_bag =bag_results_80.predict(X_test)
print("Reporte de clasifocacion forest bag:")
print()
print(confusion_matrix(y_rfc_80_bag, y_test ))
print(classification_report( y_rfc_80_bag, y_test))
micro_f1_80_bag = f1_score(y_rfc_80_bag, y_test, average='micro')
print("f1 score micro bag")
print(micro_f1_80_bag)
#fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_test, y_rfc,pos_label=1)
#auc_forest = auc(fpr_forest, tpr_forest)
MCC_forest_80_bag = matthews_corrcoef(y_rfc_80_bag , y_test)
print("MCC forest bag:")
print(MCC_forest_80_bag)
micros_f1_bag.append(micro_f1_80_bag)
MCC_bag.append(MCC_forest_80_bag)

train_90, test_90 = train_test_split(train, test_size=0.10,
random_state=42)
X_90=train_90[:,0:6]
Y_90=train_90[:,7]
y_90 = label_binarize(Y_90, classes=[0, 1])
y_90=np.ravel(y_90)
print(y_90)
rfc_90 = RandomForestClassifier(n_estimators= 1000,
criterion='entropy', oob_score=True, max_depth=100)
print("train en 90%")
print(train_90)
print(len(train_90))
rfc_90_result=rfc_90.fit(X_90, y_90)
print("Reporte de clasifocacion forest:")
print()
y_rfc_90 =rfc_90_result.predict(X_test)
print(confusion_matrix(y_rfc_90, y_test ))
print(classification_report( y_rfc_90, y_test))
print()
micro_f1_90 = f1_score(y_rfc_90, y_test, average='micro')
print("f1 score micro")
print(micro_f1_90)
OOB_90 = rfc_90_result.oob_score_
print("OOB error:")
print(OOB_90)
IMP_90 = rfc_90_result.feature_importances_.argsort()
print("Mejores caracteristicas")
print(IMP_90)
#fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_test, y_rfc,pos_label=1)
#auc_forest = auc(fpr_forest, tpr_forest)
MCC_forest_90 = matthews_corrcoef(y_rfc_90, y_test)
print("MCC forest:")
print(MCC_forest_90)
micros_f1.append(micro_f1_90)
MCC.append(MCC_forest_90)

bag_90=BaggingClassifier(rfc_90,
n_estimators=50, random_state=0)
bag_results_90=bag_90.fit(X_90, y_90)
y_rfc_90_bag =bag_results_90.predict(X_test)
print("Reporte de clasifocacion forest bag:")
print()
print(confusion_matrix(y_rfc_90_bag, y_test ))
print(classification_report( y_rfc_90_bag, y_test))
micro_f1_90_bag = f1_score(y_rfc_90_bag, y_test, average='micro')
print("f1 score micro bag")
print(micro_f1_90_bag)
#fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_test, y_rfc,pos_label=1)
#auc_forest = auc(fpr_forest, tpr_forest)
MCC_forest_90_bag = matthews_corrcoef(y_rfc_90_bag , y_test)
print("MCC forest bag:")
print(MCC_forest_90_bag)
micros_f1_bag.append(micro_f1_90_bag)
MCC_bag.append(MCC_forest_90_bag)
#print(x_train[...,0:6])
#print(len(x_train))
#x_train_1, x_test_1, y_train_1, y_test_1 = train_test_split(X ,y, test_size=0.30,random_state=42)
#print("s1")
#print(s1)
#print(len(s1))
X_train=train[:,0:6]
Y_train=train[:,7]
y = label_binarize(Y_train, classes=[0, 1])
y = np.ravel(y)
#print(y)
#print(train.size)
#print("train en total")
#print(train)
#print(len(train))
rfc = RandomForestClassifier(n_estimators= 1000,
criterion='entropy', oob_score=True, max_depth=100)
print("train with all 70%")
#print(train_80)
print(len(train))
print(len(X_train))
print(len(y))
rfc_result=rfc.fit(X_train, y)
print("Reporte de clasifocacion forest:")
print()
y_rfc =rfc_result.predict(X_test)
print(confusion_matrix(y_rfc, y_test ))
print(classification_report( y_rfc, y_test))
print()
micro_f1 = f1_score(y_rfc, y_test, average='micro')
print("f1 score micro")
print(micro_f1)
OOB = rfc_result.oob_score_
print("OOB error:")
print(OOB)
IMP = rfc_result.feature_importances_.argsort()
print("Mejores caracteristicas")
print(IMP)
#fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_test, y_rfc,pos_label=1)
#auc_forest = auc(fpr_forest, tpr_forest)
MCC_forest = matthews_corrcoef(y_rfc, y_test)
print("MCC forest:")
print(MCC_forest)
micros_f1.append(micro_f1)
MCC.append(MCC_forest)

bag=BaggingClassifier(rfc,
n_estimators=50, random_state=0)
bag_results= bag.fit(X_train, y)
y_rfc_bag = bag_results.predict(X_test)
print("Reporte de clasifocacion forest bag:")
print()
print(confusion_matrix(y_rfc_bag, y_test ))
print(classification_report( y_rfc_bag, y_test))
micro_f1_bag = f1_score(y_rfc_bag, y_test, average='micro')
print("f1 score micro bag")
print(micro_f1_bag)
#fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_test, y_rfc,pos_label=1)
#auc_forest = auc(fpr_forest, tpr_forest)
MCC_forest_bag = matthews_corrcoef(y_rfc_bag , y_test)
print("MCC forest bag:")
print(MCC_forest_bag)
micros_f1_bag.append(micro_f1_bag)
MCC_bag.append(MCC_forest_bag)

x_axis = [i for i in range(10,110,10)]
print("x axis")
print(x_axis)

plt.plot(x_axis, micros_f1, marker='o', color='red',
         label='RF' )
plt.plot(x_axis, micros_f1_bag, marker='o', color='blue',
          label='Bagging Classifier with RF' )
plt.xlabel('% Total train data',fontsize = 10)
plt.ylabel('Average Micro F1-Score',fontsize = 10)
plt.title('Random Forest using Depth=100',fontsize = 12)
plt.legend(loc="lower right",fontsize = 10 ,ncol=1)
plt.show()


plt.plot(x_axis, MCC, marker='o', color='red',
         label='RF' )
plt.plot(x_axis, MCC_bag, marker='o', color='blue',
          label='Bagging Classifier with RF' )
plt.xlabel('Using % total train data',fontsize = 10)
plt.ylabel('MCC Rate',fontsize = 10)
plt.title('Random Forest using Depth=100',fontsize = 12)
plt.legend(loc="lower right",fontsize = 10 ,ncol=1)
plt.show()
